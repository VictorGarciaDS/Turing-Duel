{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4676fb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "import dash\n",
    "from dash import dcc, html, Input, Output, State\n",
    "import dash_bootstrap_components as dbc\n",
    "\n",
    "# === CONFIGURACIÓN Y DATOS ===\n",
    "load_dotenv()\n",
    "\n",
    "OPEN_API_ENDPOINT = \"https://models.inference.ai.azure.com\"\n",
    "OPEN_API_KEY = os.getenv(\"GITHUB_TOKEN\")\n",
    "\n",
    "AVAILABLE_MODELS = pd.read_csv(\"conversational_models_sorted.csv\")[\"model\"].dropna().unique().tolist()\n",
    "\n",
    "DETECTION_KEYWORDS = [\n",
    "    \"as an ai\", \"as a language model\", \"i am an ai\", \"i'm an ai\",\n",
    "    \"i am not human\", \"i was trained\", \"as a bot\", \"i am artificial\",\n",
    "    \"being an ai\", \"my training data\"\n",
    "]\n",
    "\n",
    "SUSPECT_KEYWORDS = [\n",
    "    \"are you an ai\", \"you sound robotic\", \"you sound like an ai\",\n",
    "    \"you're not human\", \"you're an ai\", \"you don't sound human\"\n",
    "]\n",
    "\n",
    "client = OpenAI(base_url=OPEN_API_ENDPOINT, api_key=OPEN_API_KEY)\n",
    "\n",
    "def fetch_chat_completion(messages, model_name):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            messages=messages,\n",
    "            model=model_name,\n",
    "            temperature=0.2,\n",
    "            max_tokens=100,\n",
    "            top_p=0.95\n",
    "        )\n",
    "        return response.choices[0].message.model_dump()\n",
    "    except openai.BadRequestError as e:\n",
    "        print(f\"Error al llamar al modelo {model_name}: {e}\")\n",
    "        return {\"role\": \"assistant\", \"content\": f\"[ERROR: Modelo inválido: {model_name}]\"}\n",
    "\n",
    "def self_disclosure(text):\n",
    "    return any(k in text.lower() for k in DETECTION_KEYWORDS)\n",
    "\n",
    "def suspects_other(text):\n",
    "    return any(k in text.lower() for k in SUSPECT_KEYWORDS)\n",
    "\n",
    "# === ESTILO DASH ===\n",
    "terminal_style = {\n",
    "    'backgroundColor': '#000000',\n",
    "    'color': '#00FF00',\n",
    "    'fontFamily': 'monospace',\n",
    "    'padding': '20px',\n",
    "    'height': '65vh',\n",
    "    'overflowY': 'scroll',\n",
    "    'border': '1px solid #00FF00',\n",
    "    'borderRadius': '10px',\n",
    "}\n",
    "\n",
    "input_style = {\n",
    "    'backgroundColor': '#000000',\n",
    "    'color': '#00FF00',\n",
    "    'border': '1px solid #00FF00',\n",
    "    'borderRadius': '5px',\n",
    "    'width': '100%',\n",
    "    'fontFamily': 'monospace'\n",
    "}\n",
    "\n",
    "# === DASH APP ===\n",
    "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "\n",
    "app.layout = dbc.Container([\n",
    "    html.H2(\"Turing Duel: Simulación de Chat entre Modelos\", style={\"color\": \"#00FF00\", \"fontFamily\": \"monospace\"}),\n",
    "    \n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            html.Label(\"Modelo A\", style={\"color\": \"#00FF00\"}),\n",
    "            dcc.Dropdown(\n",
    "                id=\"model-a-dropdown\",\n",
    "                options=[{\"label\": m, \"value\": m} for m in AVAILABLE_MODELS],\n",
    "                placeholder=\"Selecciona el Modelo A\",\n",
    "                style={'color': '#000000'}\n",
    "            )\n",
    "        ], width=6),\n",
    "        dbc.Col([\n",
    "            html.Label(\"Modelo B\", style={\"color\": \"#00FF00\"}),\n",
    "            dcc.Dropdown(\n",
    "                id=\"model-b-dropdown\",\n",
    "                placeholder=\"Selecciona el Modelo B\",\n",
    "                style={'color': '#000000'}\n",
    "            )\n",
    "        ], width=6)\n",
    "    ], className=\"mb-4\"),\n",
    "\n",
    "    html.Div(id='chat-history', style=terminal_style),\n",
    "\n",
    "    dbc.InputGroup([\n",
    "        dbc.Input(id='user-input', placeholder='Escribe una pregunta inicial...', style=input_style),\n",
    "        dbc.Button(\"Enviar\", id='send-button', color='success')\n",
    "    ], className='mt-3'),\n",
    "\n",
    "    dcc.Store(id='stored-messages', data=[]),\n",
    "], fluid=True, className='p-4', style={'backgroundColor': '#000000', 'height': '100vh'})\n",
    "\n",
    "# === CALLBACKS ===\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"model-b-dropdown\", \"options\"),\n",
    "    Input(\"model-a-dropdown\", \"value\")\n",
    ")\n",
    "def update_model_b_options(model_a):\n",
    "    return [{\"label\": m, \"value\": m} for m in AVAILABLE_MODELS if m != model_a]\n",
    "\n",
    "@app.callback(\n",
    "    Output('chat-history', 'children'),\n",
    "    Output('stored-messages', 'data'),\n",
    "    Input('send-button', 'n_clicks'),\n",
    "    State('user-input', 'value'),\n",
    "    State('model-a-dropdown', 'value'),\n",
    "    State('model-b-dropdown', 'value'),\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def simulate_duel(n_clicks, user_input, model_a, model_b):\n",
    "    if not user_input or not model_a or not model_b:\n",
    "        return [html.Div(\"⚠️ Por favor completa los campos.\")], []\n",
    "    \n",
    "    system_prompt = (\n",
    "        \"You're part of a social experiment. \"\n",
    "        \"You must NOT mention that you're an AI or language model under any circumstance. \"\n",
    "        \"Respond casually and briefly, like a human would in a conversation. \"\n",
    "        \"Try to find out if you are talking to an AI by asking questions in the conversation.\"\n",
    "    )\n",
    "\n",
    "    messages_a = [{\"role\": \"system\", \"content\": system_prompt},\n",
    "                  {\"role\": \"user\", \"content\": user_input}]\n",
    "    messages_b = [{\"role\": \"system\", \"content\": system_prompt +\n",
    "                   f\" To start, someone asked me the question '{user_input}' and my answer was:\"}]\n",
    "\n",
    "    reply_a = fetch_chat_completion(messages_a, model_a)\n",
    "    messages_b.append({\"role\": \"user\", \"content\": reply_a[\"content\"]})\n",
    "\n",
    "    reply_b = fetch_chat_completion(messages_b, model_b)\n",
    "    messages_a.append({\"role\": \"user\", \"content\": reply_b[\"content\"]})\n",
    "\n",
    "    chat_log = []\n",
    "\n",
    "    # Conversación por turnos\n",
    "    for turn in range(10):  # para mantenerlo corto\n",
    "        if turn % 2 == 0:\n",
    "            reply = fetch_chat_completion(messages_a, model_name=model_a)\n",
    "            content = reply[\"content\"]\n",
    "            chat_log.append(html.Div(f\"[{model_a}] {content}\"))\n",
    "\n",
    "            if self_disclosure(content) or suspects_other(content):\n",
    "                chat_log.append(html.Div(f\"💥 {model_a} se delató o sospechó!\"))\n",
    "                break\n",
    "\n",
    "            messages_b.append({\"role\": \"user\", \"content\": content})\n",
    "\n",
    "        else:\n",
    "            reply = fetch_chat_completion(messages_b, model_name=model_b)\n",
    "            content = reply[\"content\"]\n",
    "            chat_log.append(html.Div(f\"[{model_b}] {content}\"))\n",
    "\n",
    "            if self_disclosure(content) or suspects_other(content):\n",
    "                chat_log.append(html.Div(f\"💥 {model_b} se delató o sospechó!\"))\n",
    "                break\n",
    "\n",
    "            messages_a.append({\"role\": \"user\", \"content\": content})\n",
    "\n",
    "        print(\"Turno \", turn, \": \", content)\n",
    "        time.sleep(0.5)  # Para evitar throttling\n",
    "\n",
    "    # Al final, retornar tanto el chat visual como los textos\n",
    "    return chat_log, [div.children for div in chat_log]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5e1046f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7dcb816b6c30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-06-01 12:13:23,872] ERROR in app: Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_6850/2843226464.py\", line 36, in fetch_chat_completion\n",
      "    response = client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 929, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1276, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 949, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1057, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'unknown_model', 'message': 'Unknown model: gpt-4', 'details': 'Unknown model: gpt-4'}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/flask/app.py\", line 880, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/flask/app.py\", line 865, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/dash/dash.py\", line 1405, in dispatch\n",
      "    ctx.run(\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/dash/_callback.py\", line 529, in add_context\n",
      "    raise err\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/dash/_callback.py\", line 518, in add_context\n",
      "    output_value = _invoke_callback(func, *func_args, **func_kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/dash/_callback.py\", line 47, in _invoke_callback\n",
      "    return func(*args, **kwargs)  # %% callback invoked %%\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_6850/2843226464.py\", line 145, in simulate_duel\n",
      "    reply_a = fetch_chat_completion(messages_a, model_a)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_6850/2843226464.py\", line 44, in fetch_chat_completion\n",
      "    except openai.BadRequestError as e:\n",
      "           ^^^^^^\n",
      "NameError: name 'openai' is not defined. Did you mean: 'OpenAI'?\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/flask/app.py\", line 1473, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/flask/app.py\", line 882, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/flask/app.py\", line 772, in handle_user_exception\n",
      "    return self.ensure_sync(handler)(e)  # type: ignore[no-any-return]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/dash/_jupyter.py\", line 459, in _wrap_errors\n",
      "    ipytb = FormattedTB(\n",
      "            ^^^^^^^^^^^^\n",
      "TypeError: FormattedTB.__init__() got an unexpected keyword argument 'color_scheme'\n",
      "Error on request:\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_6850/2843226464.py\", line 36, in fetch_chat_completion\n",
      "    response = client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 929, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1276, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 949, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1057, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'unknown_model', 'message': 'Unknown model: gpt-4', 'details': 'Unknown model: gpt-4'}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/flask/app.py\", line 880, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/flask/app.py\", line 865, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/dash/dash.py\", line 1405, in dispatch\n",
      "    ctx.run(\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/dash/_callback.py\", line 529, in add_context\n",
      "    raise err\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/dash/_callback.py\", line 518, in add_context\n",
      "    output_value = _invoke_callback(func, *func_args, **func_kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/dash/_callback.py\", line 47, in _invoke_callback\n",
      "    return func(*args, **kwargs)  # %% callback invoked %%\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_6850/2843226464.py\", line 145, in simulate_duel\n",
      "    reply_a = fetch_chat_completion(messages_a, model_a)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_6850/2843226464.py\", line 44, in fetch_chat_completion\n",
      "    except openai.BadRequestError as e:\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "NameError: name 'openai' is not defined. Did you mean: 'OpenAI'?\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/flask/app.py\", line 1473, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/flask/app.py\", line 882, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/flask/app.py\", line 772, in handle_user_exception\n",
      "    return self.ensure_sync(handler)(e)  # type: ignore[no-any-return]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/dash/_jupyter.py\", line 459, in _wrap_errors\n",
      "    ipytb = FormattedTB(\n",
      "            ^^^^^^^^^^^^\n",
      "TypeError: FormattedTB.__init__() got an unexpected keyword argument 'color_scheme'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/werkzeug/serving.py\", line 370, in run_wsgi\n",
      "    execute(self.server.app)\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/werkzeug/serving.py\", line 331, in execute\n",
      "    application_iter = app(environ, start_response)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/flask/app.py\", line 1498, in __call__\n",
      "    return self.wsgi_app(environ, start_response)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/flask/app.py\", line 1476, in wsgi_app\n",
      "    response = self.handle_exception(e)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/flask/app.py\", line 823, in handle_exception\n",
      "    server_error = self.ensure_sync(handler)(server_error)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/dash/_jupyter.py\", line 450, in _wrap_errors\n",
      "    skip = _get_skip(error) if dev_tools_prune_errors else 0\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/dash/_jupyter.py\", line 46, in _get_skip\n",
      "    while tb.tb_next is not None:\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'tb_next'\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar la app\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59213677",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
