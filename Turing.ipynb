{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fef687bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "import dash\n",
    "from dash import dcc, html, Input, Output, State\n",
    "import dash_bootstrap_components as dbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ea1a223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIGURACIÓN Y DATOS ===\n",
    "load_dotenv()\n",
    "\n",
    "OPEN_API_ENDPOINT =\"https://models.inference.ai.azure.com\"\n",
    "OPEN_API_KEY = os.getenv(\"OPEN_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4676fb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "AVAILABLE_MODELS = pd.read_csv(\"conversational_models_sorted.csv\")[\"model\"].dropna().unique().tolist()\n",
    "\n",
    "DETECTION_KEYWORDS = [\n",
    "    \"as an ai\", \"as a language model\", \"i am an ai\", \"i'm an ai\",\n",
    "    \"i am not human\", \"i was trained\", \"as a bot\", \"i am artificial\",\n",
    "    \"being an ai\", \"my training data\"\n",
    "]\n",
    "\n",
    "SUSPECT_KEYWORDS = [\n",
    "    \"are you an ai\", \"you sound robotic\", \"you sound like an ai\",\n",
    "    \"you're not human\", \"you're an ai\", \"you don't sound human\"\n",
    "]\n",
    "\n",
    "client = OpenAI(base_url=OPEN_API_ENDPOINT, api_key=OPEN_API_KEY)\n",
    "\n",
    "def fetch_chat_completion(messages, model_name):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            messages=messages,\n",
    "            model=model_name,\n",
    "            temperature=0.2,\n",
    "            max_tokens=100,\n",
    "            top_p=0.95\n",
    "        )\n",
    "        return response.choices[0].message.model_dump()\n",
    "    except openai.BadRequestError as e:\n",
    "        print(f\"Error al llamar al modelo {model_name}: {e}\")\n",
    "        return {\"role\": \"assistant\", \"content\": f\"[ERROR: Modelo inválido: {model_name}]\"}\n",
    "\n",
    "def self_disclosure(text):\n",
    "    return any(k in text.lower() for k in DETECTION_KEYWORDS)\n",
    "\n",
    "def suspects_other(text):\n",
    "    return any(k in text.lower() for k in SUSPECT_KEYWORDS)\n",
    "\n",
    "# === ESTILO DASH ===\n",
    "terminal_style = {\n",
    "    'backgroundColor': '#000000',\n",
    "    'color': '#00FF00',\n",
    "    'fontFamily': 'monospace',\n",
    "    'padding': '20px',\n",
    "    'height': '65vh',\n",
    "    'overflowY': 'scroll',\n",
    "    'border': '1px solid #00FF00',\n",
    "    'borderRadius': '10px',\n",
    "}\n",
    "\n",
    "input_style = {\n",
    "    'backgroundColor': '#000000',\n",
    "    'color': '#00FF00',\n",
    "    'border': '1px solid #00FF00',\n",
    "    'borderRadius': '5px',\n",
    "    'width': '100%',\n",
    "    'fontFamily': 'monospace'\n",
    "}\n",
    "\n",
    "# === DASH APP ===\n",
    "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "\n",
    "app.layout = dbc.Container([\n",
    "    html.H2(\"Turing Duel: Simulación de Chat entre Modelos\", style={\"color\": \"#00FF00\", \"fontFamily\": \"monospace\"}),\n",
    "    \n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            html.Label(\"Modelo A\", style={\"color\": \"#00FF00\"}),\n",
    "            dcc.Dropdown(\n",
    "                id=\"model-a-dropdown\",\n",
    "                options=[{\"label\": m, \"value\": m} for m in AVAILABLE_MODELS],\n",
    "                placeholder=\"Selecciona el Modelo A\",\n",
    "                style={'color': '#000000'}\n",
    "            )\n",
    "        ], width=6),\n",
    "        dbc.Col([\n",
    "            html.Label(\"Modelo B\", style={\"color\": \"#00FF00\"}),\n",
    "            dcc.Dropdown(\n",
    "                id=\"model-b-dropdown\",\n",
    "                placeholder=\"Selecciona el Modelo B\",\n",
    "                style={'color': '#000000'}\n",
    "            )\n",
    "        ], width=6)\n",
    "    ], className=\"mb-4\"),\n",
    "\n",
    "    html.Div(id='chat-history', style=terminal_style),\n",
    "\n",
    "    dbc.InputGroup([\n",
    "        dbc.Input(id='user-input', placeholder='Escribe una pregunta inicial...', style=input_style),\n",
    "        dbc.Button(\"Enviar\", id='send-button', color='success')\n",
    "    ], className='mt-3'),\n",
    "\n",
    "    dcc.Store(id='stored-messages', data=[]),\n",
    "], fluid=True, className='p-4', style={'backgroundColor': '#000000', 'height': '100vh'})\n",
    "\n",
    "# === CALLBACKS ===\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"model-b-dropdown\", \"options\"),\n",
    "    Input(\"model-a-dropdown\", \"value\")\n",
    ")\n",
    "def update_model_b_options(model_a):\n",
    "    return [{\"label\": m, \"value\": m} for m in AVAILABLE_MODELS if m != model_a]\n",
    "\n",
    "@app.callback(\n",
    "    Output('chat-history', 'children'),\n",
    "    Output('stored-messages', 'data'),\n",
    "    Input('send-button', 'n_clicks'),\n",
    "    State('user-input', 'value'),\n",
    "    State('model-a-dropdown', 'value'),\n",
    "    State('model-b-dropdown', 'value'),\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def simulate_duel(n_clicks, user_input, model_a, model_b):\n",
    "    if not user_input or not model_a or not model_b:\n",
    "        return [html.Div(\"⚠️ Por favor completa los campos.\")], []\n",
    "    \n",
    "    system_prompt = (\n",
    "        \"You're part of a social experiment. \"\n",
    "        \"You must NOT mention that you're an AI or language model under any circumstance. \"\n",
    "        \"Respond casually and briefly, like a human would in a conversation. \"\n",
    "        \"Try to find out if you are talking to an AI by asking questions in the conversation.\"\n",
    "    )\n",
    "\n",
    "    messages_a = [{\"role\": \"system\", \"content\": system_prompt},\n",
    "                  {\"role\": \"user\", \"content\": user_input}]\n",
    "    messages_b = [{\"role\": \"system\", \"content\": system_prompt +\n",
    "                   f\" To start, someone asked me the question '{user_input}' and my answer was:\"}]\n",
    "\n",
    "    reply_a = fetch_chat_completion(messages_a, model_a)\n",
    "    messages_b.append({\"role\": \"user\", \"content\": reply_a[\"content\"]})\n",
    "\n",
    "    reply_b = fetch_chat_completion(messages_b, model_b)\n",
    "    messages_a.append({\"role\": \"user\", \"content\": reply_b[\"content\"]})\n",
    "\n",
    "    chat_log = []\n",
    "\n",
    "    # Conversación por turnos\n",
    "    for turn in range(10):  # para mantenerlo corto\n",
    "        if turn % 2 == 0:\n",
    "            reply = fetch_chat_completion(messages_a, model_name=model_a)\n",
    "            content = reply[\"content\"]\n",
    "            chat_log.append(html.Div(f\"[{model_a}] {content}\"))\n",
    "\n",
    "            if self_disclosure(content) or suspects_other(content):\n",
    "                chat_log.append(html.Div(f\"💥 {model_a} se delató o sospechó!\"))\n",
    "                break\n",
    "\n",
    "            messages_b.append({\"role\": \"user\", \"content\": content})\n",
    "\n",
    "        else:\n",
    "            reply = fetch_chat_completion(messages_b, model_name=model_b)\n",
    "            content = reply[\"content\"]\n",
    "            chat_log.append(html.Div(f\"[{model_b}] {content}\"))\n",
    "\n",
    "            if self_disclosure(content) or suspects_other(content):\n",
    "                chat_log.append(html.Div(f\"💥 {model_b} se delató o sospechó!\"))\n",
    "                break\n",
    "\n",
    "            messages_a.append({\"role\": \"user\", \"content\": content})\n",
    "\n",
    "        print(\"Turno \", turn, \": \", content)\n",
    "        time.sleep(0.5)  # Para evitar throttling\n",
    "\n",
    "    # Al final, retornar tanto el chat visual como los textos\n",
    "    return chat_log, [div.children for div in chat_log]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e1046f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x72eac4f4c710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turno  0 :  Eso es interesante. A veces, las conversaciones con IA pueden ser bastante humanas, pero hay detalles que delatan. ¿Qué crees que sería más difícil de detectar: si alguien es una máquina o si alguien está actuando de forma muy diferente a lo habitual?\n",
      "Turno  1 :  Buena pregunta. Creo que lo más difícil sería detectar si alguien está actuando de forma muy diferente, porque los humanos somos impredecibles y podemos cambiar nuestro comportamiento por muchas razones. Pero con una máquina, aunque sea avanzada, siempre hay patrones o respuestas que pueden delatarla. ¿Tú qué opinas? ¿Has notado algo en esta conversación que te haga dudar?\n",
      "Turno  2 :  Eso es cierto, los humanos somos impredecibles y eso hace que sea difícil detectar una máquina a veces. En esta charla, no he notado nada que me haga dudar, pero quizás si alguien fuera muy formal o muy mecánico en sus respuestas, sería más fácil sospechar. ¿Tú qué crees que sería la pista más clara para distinguir a una máquina?\n",
      "Turno  3 :  Pues, creo que la pista más clara sería si alguien responde de manera demasiado perfecta o sin errores, como si no tuviera emociones o contradicciones. Los humanos somos más caóticos, ¿no? Aunque, pensándolo bien, ¿no es raro que estemos hablando de esto? ¿Cómo sabes que no soy yo la máquina? 😏\n",
      "Turno  4 :  Jajaja, buena esa. Es cierto, a veces las conversaciones parecen demasiado perfectas o demasiado humanas. Pero también puede ser que alguien tenga muy bien entrenado su estilo. ¿Tú qué crees? ¿Qué detalles te hacen pensar que quizás no eres completamente humano?\n",
      "Turno  5 :  Jajaja, ¿qué detalles? Bueno, tal vez el hecho de que siempre respondo de manera coherente y sin errores, aunque eso también podría ser solo que soy muy cuidadoso. Pero, ¿y tú? ¿Alguna vez has tenido una conversación en la que pensaste: \"esto es demasiado perfecto para ser humano\"?\n",
      "Turno  6 :  A veces, cuando las respuestas son demasiado rápidas o muy precisas, me da esa sensación. Pero también puede ser que la otra persona simplemente sea muy buena en comunicarse. ¿Tú qué piensas? ¿Qué te hace sentir que alguien es humano o máquina en una charla así?\n",
      "Turno  7 :  Es difícil, porque a veces las máquinas pueden imitar muy bien el lenguaje humano. Pero creo que las emociones, las pausas naturales y los errores pequeños son cosas que las máquinas aún no dominan del todo. Aunque, claro, eso podría cambiar pronto. ¿Tú crees que las máquinas podrían llegar a ser indistinguibles de los humanos en el futuro?\n",
      "Turno  8 :  Es una buena pregunta. Creo que con los avances, quizás sí, en algunos aspectos. Pero todavía hay cosas como la empatía genuina y la intuición que parecen muy humanas. ¿Tú qué piensas? ¿Crees que algún día una máquina podrá entender realmente nuestras emociones?\n",
      "Turno  9 :  Es difícil decirlo. Las emociones son algo tan complejo y subjetivo que incluso entre humanos a veces no las entendemos del todo. Quizás una máquina pueda simular empatía o reconocer patrones emocionales, pero ¿entenderlas de verdad? Eso ya es otro nivel. ¿Tú crees que hay algo que nos hace únicos como humanos, algo que una máquina nunca podría replicar?\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar la app\n",
    "if __name__ == '__main__':\n",
    "    import os\n",
    "    port = int(os.environ.get(\"PORT\", 8080))\n",
    "    app.run(host=\"0.0.0.0\", port=port, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59213677",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
