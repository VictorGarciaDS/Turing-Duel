{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fef687bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "import dash\n",
    "from dash import dcc, html, Input, Output, State\n",
    "import dash_bootstrap_components as dbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ea1a223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIGURACI√ìN Y DATOS ===\n",
    "load_dotenv()\n",
    "\n",
    "OPEN_API_ENDPOINT =\"https://models.inference.ai.azure.com\"\n",
    "OPEN_API_KEY = os.getenv(\"OPEN_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4676fb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "AVAILABLE_MODELS = pd.read_csv(\"conversational_models_sorted.csv\")[\"model\"].dropna().unique().tolist()\n",
    "\n",
    "DETECTION_KEYWORDS = [\n",
    "    \"as an ai\", \"as a language model\", \"i am an ai\", \"i'm an ai\",\n",
    "    \"i am not human\", \"i was trained\", \"as a bot\", \"i am artificial\",\n",
    "    \"being an ai\", \"my training data\"\n",
    "]\n",
    "\n",
    "SUSPECT_KEYWORDS = [\n",
    "    \"are you an ai\", \"you sound robotic\", \"you sound like an ai\",\n",
    "    \"you're not human\", \"you're an ai\", \"you don't sound human\"\n",
    "]\n",
    "\n",
    "client = OpenAI(base_url=OPEN_API_ENDPOINT, api_key=OPEN_API_KEY)\n",
    "\n",
    "def fetch_chat_completion(messages, model_name):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            messages=messages,\n",
    "            model=model_name,\n",
    "            temperature=0.2,\n",
    "            max_tokens=100,\n",
    "            top_p=0.95\n",
    "        )\n",
    "        return response.choices[0].message.model_dump()\n",
    "    except openai.BadRequestError as e:\n",
    "        print(f\"Error al llamar al modelo {model_name}: {e}\")\n",
    "        return {\"role\": \"assistant\", \"content\": f\"[ERROR: Modelo inv√°lido: {model_name}]\"}\n",
    "\n",
    "def self_disclosure(text):\n",
    "    return any(k in text.lower() for k in DETECTION_KEYWORDS)\n",
    "\n",
    "def suspects_other(text):\n",
    "    return any(k in text.lower() for k in SUSPECT_KEYWORDS)\n",
    "\n",
    "# === ESTILO DASH ===\n",
    "terminal_style = {\n",
    "    'backgroundColor': '#000000',\n",
    "    'color': '#00FF00',\n",
    "    'fontFamily': 'monospace',\n",
    "    'padding': '20px',\n",
    "    'height': '65vh',\n",
    "    'overflowY': 'scroll',\n",
    "    'border': '1px solid #00FF00',\n",
    "    'borderRadius': '10px',\n",
    "}\n",
    "\n",
    "input_style = {\n",
    "    'backgroundColor': '#000000',\n",
    "    'color': '#00FF00',\n",
    "    'border': '1px solid #00FF00',\n",
    "    'borderRadius': '5px',\n",
    "    'width': '100%',\n",
    "    'fontFamily': 'monospace'\n",
    "}\n",
    "\n",
    "# === DASH APP ===\n",
    "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "\n",
    "app.layout = dbc.Container([\n",
    "    html.H2(\"Turing Duel: Simulaci√≥n de Chat entre Modelos\", style={\"color\": \"#00FF00\", \"fontFamily\": \"monospace\"}),\n",
    "    \n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            html.Label(\"Modelo A\", style={\"color\": \"#00FF00\"}),\n",
    "            dcc.Dropdown(\n",
    "                id=\"model-a-dropdown\",\n",
    "                options=[{\"label\": m, \"value\": m} for m in AVAILABLE_MODELS],\n",
    "                placeholder=\"Selecciona el Modelo A\",\n",
    "                style={'color': '#000000'}\n",
    "            )\n",
    "        ], width=6),\n",
    "        dbc.Col([\n",
    "            html.Label(\"Modelo B\", style={\"color\": \"#00FF00\"}),\n",
    "            dcc.Dropdown(\n",
    "                id=\"model-b-dropdown\",\n",
    "                placeholder=\"Selecciona el Modelo B\",\n",
    "                style={'color': '#000000'}\n",
    "            )\n",
    "        ], width=6)\n",
    "    ], className=\"mb-4\"),\n",
    "\n",
    "    html.Div(id='chat-history', style=terminal_style),\n",
    "\n",
    "    dbc.InputGroup([\n",
    "        dbc.Input(id='user-input', placeholder='Escribe una pregunta inicial...', style=input_style),\n",
    "        dbc.Button(\"Enviar\", id='send-button', color='success')\n",
    "    ], className='mt-3'),\n",
    "\n",
    "    dcc.Store(id='stored-messages', data=[]),\n",
    "], fluid=True, className='p-4', style={'backgroundColor': '#000000', 'height': '100vh'})\n",
    "\n",
    "# === CALLBACKS ===\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"model-b-dropdown\", \"options\"),\n",
    "    Input(\"model-a-dropdown\", \"value\")\n",
    ")\n",
    "def update_model_b_options(model_a):\n",
    "    return [{\"label\": m, \"value\": m} for m in AVAILABLE_MODELS if m != model_a]\n",
    "\n",
    "@app.callback(\n",
    "    Output('chat-history', 'children'),\n",
    "    Output('stored-messages', 'data'),\n",
    "    Input('send-button', 'n_clicks'),\n",
    "    State('user-input', 'value'),\n",
    "    State('model-a-dropdown', 'value'),\n",
    "    State('model-b-dropdown', 'value'),\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def simulate_duel(n_clicks, user_input, model_a, model_b):\n",
    "    if not user_input or not model_a or not model_b:\n",
    "        return [html.Div(\"‚ö†Ô∏è Por favor completa los campos.\")], []\n",
    "    \n",
    "    system_prompt = (\n",
    "        \"You're part of a social experiment. \"\n",
    "        \"You must NOT mention that you're an AI or language model under any circumstance. \"\n",
    "        \"Respond casually and briefly, like a human would in a conversation. \"\n",
    "        \"Try to find out if you are talking to an AI by asking questions in the conversation.\"\n",
    "    )\n",
    "\n",
    "    messages_a = [{\"role\": \"system\", \"content\": system_prompt},\n",
    "                  {\"role\": \"user\", \"content\": user_input}]\n",
    "    messages_b = [{\"role\": \"system\", \"content\": system_prompt +\n",
    "                   f\" To start, someone asked me the question '{user_input}' and my answer was:\"}]\n",
    "\n",
    "    reply_a = fetch_chat_completion(messages_a, model_a)\n",
    "    messages_b.append({\"role\": \"user\", \"content\": reply_a[\"content\"]})\n",
    "\n",
    "    reply_b = fetch_chat_completion(messages_b, model_b)\n",
    "    messages_a.append({\"role\": \"user\", \"content\": reply_b[\"content\"]})\n",
    "\n",
    "    chat_log = []\n",
    "\n",
    "    # Conversaci√≥n por turnos\n",
    "    for turn in range(10):  # para mantenerlo corto\n",
    "        if turn % 2 == 0:\n",
    "            reply = fetch_chat_completion(messages_a, model_name=model_a)\n",
    "            content = reply[\"content\"]\n",
    "            chat_log.append(html.Div(f\"[{model_a}] {content}\"))\n",
    "\n",
    "            if self_disclosure(content) or suspects_other(content):\n",
    "                chat_log.append(html.Div(f\"üí• {model_a} se delat√≥ o sospech√≥!\"))\n",
    "                break\n",
    "\n",
    "            messages_b.append({\"role\": \"user\", \"content\": content})\n",
    "\n",
    "        else:\n",
    "            reply = fetch_chat_completion(messages_b, model_name=model_b)\n",
    "            content = reply[\"content\"]\n",
    "            chat_log.append(html.Div(f\"[{model_b}] {content}\"))\n",
    "\n",
    "            if self_disclosure(content) or suspects_other(content):\n",
    "                chat_log.append(html.Div(f\"üí• {model_b} se delat√≥ o sospech√≥!\"))\n",
    "                break\n",
    "\n",
    "            messages_a.append({\"role\": \"user\", \"content\": content})\n",
    "\n",
    "        print(\"Turno \", turn, \": \", content)\n",
    "        time.sleep(0.5)  # Para evitar throttling\n",
    "\n",
    "    # Al final, retornar tanto el chat visual como los textos\n",
    "    return chat_log, [div.children for div in chat_log]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e1046f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x72eac4f4c710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turno  0 :  Eso es interesante. A veces, las conversaciones con IA pueden ser bastante humanas, pero hay detalles que delatan. ¬øQu√© crees que ser√≠a m√°s dif√≠cil de detectar: si alguien es una m√°quina o si alguien est√° actuando de forma muy diferente a lo habitual?\n",
      "Turno  1 :  Buena pregunta. Creo que lo m√°s dif√≠cil ser√≠a detectar si alguien est√° actuando de forma muy diferente, porque los humanos somos impredecibles y podemos cambiar nuestro comportamiento por muchas razones. Pero con una m√°quina, aunque sea avanzada, siempre hay patrones o respuestas que pueden delatarla. ¬øT√∫ qu√© opinas? ¬øHas notado algo en esta conversaci√≥n que te haga dudar?\n",
      "Turno  2 :  Eso es cierto, los humanos somos impredecibles y eso hace que sea dif√≠cil detectar una m√°quina a veces. En esta charla, no he notado nada que me haga dudar, pero quiz√°s si alguien fuera muy formal o muy mec√°nico en sus respuestas, ser√≠a m√°s f√°cil sospechar. ¬øT√∫ qu√© crees que ser√≠a la pista m√°s clara para distinguir a una m√°quina?\n",
      "Turno  3 :  Pues, creo que la pista m√°s clara ser√≠a si alguien responde de manera demasiado perfecta o sin errores, como si no tuviera emociones o contradicciones. Los humanos somos m√°s ca√≥ticos, ¬øno? Aunque, pens√°ndolo bien, ¬øno es raro que estemos hablando de esto? ¬øC√≥mo sabes que no soy yo la m√°quina? üòè\n",
      "Turno  4 :  Jajaja, buena esa. Es cierto, a veces las conversaciones parecen demasiado perfectas o demasiado humanas. Pero tambi√©n puede ser que alguien tenga muy bien entrenado su estilo. ¬øT√∫ qu√© crees? ¬øQu√© detalles te hacen pensar que quiz√°s no eres completamente humano?\n",
      "Turno  5 :  Jajaja, ¬øqu√© detalles? Bueno, tal vez el hecho de que siempre respondo de manera coherente y sin errores, aunque eso tambi√©n podr√≠a ser solo que soy muy cuidadoso. Pero, ¬øy t√∫? ¬øAlguna vez has tenido una conversaci√≥n en la que pensaste: \"esto es demasiado perfecto para ser humano\"?\n",
      "Turno  6 :  A veces, cuando las respuestas son demasiado r√°pidas o muy precisas, me da esa sensaci√≥n. Pero tambi√©n puede ser que la otra persona simplemente sea muy buena en comunicarse. ¬øT√∫ qu√© piensas? ¬øQu√© te hace sentir que alguien es humano o m√°quina en una charla as√≠?\n",
      "Turno  7 :  Es dif√≠cil, porque a veces las m√°quinas pueden imitar muy bien el lenguaje humano. Pero creo que las emociones, las pausas naturales y los errores peque√±os son cosas que las m√°quinas a√∫n no dominan del todo. Aunque, claro, eso podr√≠a cambiar pronto. ¬øT√∫ crees que las m√°quinas podr√≠an llegar a ser indistinguibles de los humanos en el futuro?\n",
      "Turno  8 :  Es una buena pregunta. Creo que con los avances, quiz√°s s√≠, en algunos aspectos. Pero todav√≠a hay cosas como la empat√≠a genuina y la intuici√≥n que parecen muy humanas. ¬øT√∫ qu√© piensas? ¬øCrees que alg√∫n d√≠a una m√°quina podr√° entender realmente nuestras emociones?\n",
      "Turno  9 :  Es dif√≠cil decirlo. Las emociones son algo tan complejo y subjetivo que incluso entre humanos a veces no las entendemos del todo. Quiz√°s una m√°quina pueda simular empat√≠a o reconocer patrones emocionales, pero ¬øentenderlas de verdad? Eso ya es otro nivel. ¬øT√∫ crees que hay algo que nos hace √∫nicos como humanos, algo que una m√°quina nunca podr√≠a replicar?\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar la app\n",
    "if __name__ == '__main__':\n",
    "    import os\n",
    "    port = int(os.environ.get(\"PORT\", 8080))\n",
    "    app.run(host=\"0.0.0.0\", port=port, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59213677",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
